{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5d7c8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "from boruta import BorutaPy as boruta\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from numpy import *\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962c185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d42cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Details/dataset/SentimentbasedRecoEngine/sample30.csv', index_col=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "be757cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n",
      "271\n",
      "270\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "print(data['manufacturer'].nunique())\n",
    "print(data['name'].nunique())\n",
    "print(data['categories'].nunique())\n",
    "print(data['brand'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "66ba1231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29936 entries, 0 to 29999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   id                    29936 non-null  object\n",
      " 1   brand                 29936 non-null  object\n",
      " 2   categories            29936 non-null  object\n",
      " 3   manufacturer          29795 non-null  object\n",
      " 4   name                  29936 non-null  object\n",
      " 5   reviews_date          29896 non-null  object\n",
      " 6   reviews_didPurchase   15931 non-null  object\n",
      " 7   reviews_doRecommend   27395 non-null  object\n",
      " 8   reviews_rating        29936 non-null  int64 \n",
      " 9   reviews_text          29936 non-null  object\n",
      " 10  reviews_title         29747 non-null  object\n",
      " 11  reviews_userCity      1900 non-null   object\n",
      " 12  reviews_userProvince  166 non-null    object\n",
      " 13  reviews_username      29936 non-null  object\n",
      " 14  user_sentiment        29936 non-null  object\n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data[(data['reviews_username'].isnull()==False) & (data['user_sentiment'].isnull()==False)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba2d15fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    26579\n",
       "Negative     3357\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d8bd1ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b8bcc82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_sentiment  reviews_doRecommend\n",
       "Negative        False                    556\n",
       "                True                    2380\n",
       "Positive        False                    994\n",
       "                True                   23465\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['user_sentiment', 'reviews_doRecommend'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0896caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29936, 12)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['id', 'brand', 'categories', 'manufacturer', 'name', 'reviews_date', 'reviews_text', 'reviews_title', 'reviews_doRecommend',\n",
    "         'reviews_rating', 'reviews_username', 'user_sentiment']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fbe76962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "brand                     0\n",
       "categories                0\n",
       "manufacturer            141\n",
       "name                      0\n",
       "reviews_date             40\n",
       "reviews_text              0\n",
       "reviews_title           189\n",
       "reviews_doRecommend    2541\n",
       "reviews_rating            0\n",
       "reviews_username          0\n",
       "user_sentiment            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f71cd1a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "df['reviews_title'] = df['reviews_title'].astype('O')\n",
    "cnt = [i for i in df['reviews_title'].to_list() if isinstance(i, float)]\n",
    "print(cnt)\n",
    "cnt = [i for i in df['reviews_text'].to_list() if i.isnumeric()]\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7e639306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_title'] = df['reviews_title'].fillna('NF')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0e05ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.loc[i,'reviews_title'] == 'NF':\n",
    "        if df.loc[i, 'user_sentiment'] == 'Positive':\n",
    "            df.loc[i,'reviews_title']='Good'\n",
    "        if df.loc[i, 'user_sentiment'] == 'Negative':\n",
    "            df.loc[i,'reviews_title']='Bad'\n",
    "\n",
    "df['manufacturer'].fillna(df['brand'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8705563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# add stemming and lemmatisation in the preprocess function\n",
    "def preprocess(document):\n",
    "    'changes document to lower case and removes stopwords'\n",
    "    document = document.lower()\n",
    "    words = word_tokenize(document)\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    document = \" \".join(words)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e0db3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_text'] = df['reviews_title']+' '+df['reviews_text']\n",
    "df['reviews_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4a64318c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29936, 13)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['proc_reviews_text'] = df['reviews_text'].apply(preprocess)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "74d788e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "      <th>proc_reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>Just Awesome i love this album. it's very good...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "      <td>awesom love album . 's good . hip hop side cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>Good Good flavor. This review was collected as...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "      <td>good good flavor . review collect part promot .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  Just Awesome i love this album. it's very good...  Just Awesome   \n",
       "1  Good Good flavor. This review was collected as...          Good   \n",
       "\n",
       "  reviews_doRecommend  reviews_rating reviews_username user_sentiment  \\\n",
       "0                 NaN               5           joshua       Positive   \n",
       "1                 NaN               5        dorothy w       Positive   \n",
       "\n",
       "                                   proc_reviews_text  \n",
       "0  awesom love album . 's good . hip hop side cur...  \n",
       "1    good good flavor . review collect part promot .  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ddf31ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('final_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6b0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3691ca5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29936 entries, 0 to 29935\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   29936 non-null  object\n",
      " 1   brand                29936 non-null  object\n",
      " 2   categories           29936 non-null  object\n",
      " 3   manufacturer         29936 non-null  object\n",
      " 4   name                 29936 non-null  object\n",
      " 5   reviews_date         29896 non-null  object\n",
      " 6   reviews_text         29936 non-null  object\n",
      " 7   reviews_title        29936 non-null  object\n",
      " 8   reviews_doRecommend  27395 non-null  object\n",
      " 9   reviews_rating       29936 non-null  int64 \n",
      " 10  reviews_username     29936 non-null  object\n",
      " 11  user_sentiment       29936 non-null  object\n",
      " 12  proc_reviews_text    29936 non-null  object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('final_data.csv', index_col=None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ad986e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26579\n",
       "0     3357\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'] = df['user_sentiment'].map({'Positive':1, 'Negative':0})\n",
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c62003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327ab1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"awesom love album . 's good . hip hop side current pop sound .. hype ! listen everyday gym ! give 5star rate way . metaphor crazi .\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'proc_reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad95289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['proc_reviews_text'], df['user_sentiment']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['proc_reviews_text'], df['user_sentiment'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a374db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffedd7a",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "1. TF-IDF Vectorizer \n",
    "2. Bag-of-Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c133252",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_model = tfidf_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17442a6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22452, 13290)\n"
     ]
    }
   ],
   "source": [
    "xtrain_tfi = tfidf_model.transform(xtrain)\n",
    "xtest_tfi  = tfidf_model.transform(xtest)\n",
    "\n",
    "xdf_tf = pd.DataFrame(xtrain_tfi.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "print(xdf_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a493c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22b28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow_model = bow_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e27934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22452, 13076)\n"
     ]
    }
   ],
   "source": [
    "xtrain_bow = bow_model.transform(xtrain)\n",
    "xtest_bow  = bow_model.transform(xtest)\n",
    "\n",
    "xdf_bow = pd.DataFrame(xtrain_bow.toarray(), columns=bow_vectorizer.get_feature_names())\n",
    "print(xdf_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47965f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22452, 13290), (7484, 13290), (22452, 13076), (7484, 13076))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfi.shape, xtest_tfi.shape, xtrain_bow.shape, xtest_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1139c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54158010",
   "metadata": {},
   "source": [
    "## Class Imbalance Fix\n",
    "1. TF-IDF features\n",
    "2. Bag-of-Words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4933d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_train_tf, y_train_tf = oversample.fit_resample(xtrain_tfi, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c9c10ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    19937\n",
       " 1    19937\n",
       " Name: user_sentiment, dtype: int64,\n",
       " (39874, 13290))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf.value_counts(), x_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae5bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea2a74b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "x_train_bw, y_train_bw = oversample.fit_resample(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c63333c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    19937\n",
       " 1    19937\n",
       " Name: user_sentiment, dtype: int64,\n",
       " (39874, 13076))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bw.value_counts(), x_train_bw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87f8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4326d1b",
   "metadata": {},
   "source": [
    "## Data Modelling\n",
    "1. TF-IDF\n",
    "2. Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe8ccd",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58fadb3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(penalty=\"l2\", random_state=42, C=3.5)\n",
    "logreg1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train = logreg1.predict(x_train_tf)\n",
    "pred_test  = logreg1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22515775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     20838\n",
      "           1       0.92      0.96      0.94     19024\n",
      "\n",
      "    accuracy                           0.94     39862\n",
      "   macro avg       0.94      0.94      0.94     39862\n",
      "weighted avg       0.94      0.94      0.94     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.45      0.56      1396\n",
      "           1       0.88      0.97      0.92      6088\n",
      "\n",
      "    accuracy                           0.87      7484\n",
      "   macro avg       0.82      0.71      0.74      7484\n",
      "weighted avg       0.86      0.87      0.86      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afe27fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701229289150187 0.7087261708881014\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test, ytest), roc_auc_score(pred_test, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362c84a",
   "metadata": {},
   "source": [
    "Old: Train accuracy: 0.8899546647578144 . Test accuracy: 0.8838659392049883\n",
    "Train AUC: 0.9449458052810008. Test AUC: 0.5255060352831941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268e720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cd4750c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(penalty=\"l2\", random_state=42, C=3.5)\n",
    "logreg2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train2 = logreg2.predict(x_train_bw)\n",
    "pred_test2  = logreg2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "531b0a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     20036\n",
      "           1       0.96      0.97      0.97     19826\n",
      "\n",
      "    accuracy                           0.97     39862\n",
      "   macro avg       0.97      0.97      0.97     39862\n",
      "weighted avg       0.97      0.97      0.97     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.51      0.58      1076\n",
      "           1       0.92      0.96      0.94      6408\n",
      "\n",
      "    accuracy                           0.89      7484\n",
      "   macro avg       0.79      0.73      0.76      7484\n",
      "weighted avg       0.88      0.89      0.89      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08e235a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892036344200962 0.7343457759584905\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test2, ytest), roc_auc_score(pred_test2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a66aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16968f09",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef875c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb1 = BernoulliNB()\n",
    "bnb1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_nb1 = bnb1.predict(x_train_tf)\n",
    "pred_test_nb1  = bnb1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2336a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76     15055\n",
      "           1       0.91      0.73      0.81     24807\n",
      "\n",
      "    accuracy                           0.79     39862\n",
      "   macro avg       0.79      0.81      0.79     39862\n",
      "weighted avg       0.82      0.79      0.79     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.29      0.30       935\n",
      "           1       0.90      0.91      0.91      6549\n",
      "\n",
      "    accuracy                           0.84      7484\n",
      "   macro avg       0.61      0.60      0.61      7484\n",
      "weighted avg       0.83      0.84      0.83      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_nb1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_nb1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be991317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835515766969535 0.6011723225083145\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_nb1, ytest), roc_auc_score(pred_test_nb1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5962232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3427a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb2 = BernoulliNB()\n",
    "bnb2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_nb2 = bnb2.predict(x_train_bw)\n",
    "pred_test_nb2  = bnb2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "454c685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86     22807\n",
      "           1       0.78      0.91      0.84     17055\n",
      "\n",
      "    accuracy                           0.85     39862\n",
      "   macro avg       0.85      0.86      0.85     39862\n",
      "weighted avg       0.86      0.85      0.85     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.20      0.29      2029\n",
      "           1       0.76      0.92      0.83      5455\n",
      "\n",
      "    accuracy                           0.73      7484\n",
      "   macro avg       0.62      0.56      0.56      7484\n",
      "weighted avg       0.69      0.73      0.68      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_nb2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_nb2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c3c0fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272848743987173 0.5626644181820071\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_nb2, ytest), roc_auc_score(pred_test_nb2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e9fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5853b46d",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38ff411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier()\n",
    "xgb1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_xg1 = xgb1.predict(x_train_tf)\n",
    "pred_test_xg1  = xgb1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366154d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     19914\n",
      "           1       0.95      0.95      0.95     19960\n",
      "\n",
      "    accuracy                           0.95     39874\n",
      "   macro avg       0.95      0.95      0.95     39874\n",
      "weighted avg       0.95      0.95      0.95     39874\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.54      1013\n",
      "           1       0.92      0.95      0.93      6471\n",
      "\n",
      "    accuracy                           0.88      7484\n",
      "   macro avg       0.76      0.72      0.74      7484\n",
      "weighted avg       0.88      0.88      0.88      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_xg1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_xg1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5399073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8849545697487974 0.7186535630223871\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_xg1, ytest), roc_auc_score(pred_test_xg1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929964d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fc94162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier()\n",
    "xgb2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_xg2 = xgb2.predict(x_train_bw)\n",
    "pred_test_xg2  = xgb2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e56b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     19119\n",
      "           1       0.98      0.94      0.96     20755\n",
      "\n",
      "    accuracy                           0.96     39874\n",
      "   macro avg       0.96      0.96      0.96     39874\n",
      "weighted avg       0.96      0.96      0.96     39874\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.66      0.53       561\n",
      "           1       0.97      0.93      0.95      6923\n",
      "\n",
      "    accuracy                           0.91      7484\n",
      "   macro avg       0.70      0.79      0.74      7484\n",
      "weighted avg       0.93      0.91      0.92      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_xg2, y_train_bw)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_xg2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41fe6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111437733832175 0.7947155146643636\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_xg2, ytest), roc_auc_score(pred_test_xg2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbdc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a032bd5",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2ad05734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier()\n",
    "rf1.fit(x_train_tf, y_train_tf)\n",
    "\n",
    "pred_train_rf1 = rf1.predict(x_train_tf)\n",
    "pred_test_rf1  = rf1.predict(xtest_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45f3eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19933\n",
      "           1       1.00      1.00      1.00     19929\n",
      "\n",
      "    accuracy                           1.00     39862\n",
      "   macro avg       1.00      1.00      1.00     39862\n",
      "weighted avg       1.00      1.00      1.00     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.56      0.46       576\n",
      "           1       0.96      0.93      0.94      6908\n",
      "\n",
      "    accuracy                           0.90      7484\n",
      "   macro avg       0.68      0.75      0.70      7484\n",
      "weighted avg       0.92      0.90      0.91      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_rf1, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_rf1, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01915737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981827899518974 0.74513195248665\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_rf1, ytest), roc_auc_score(pred_test_rf1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d7506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b72709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier()\n",
    "rf2.fit(x_train_bw, y_train_bw)\n",
    "\n",
    "pred_train_rf2 = rf2.predict(x_train_bw)\n",
    "pred_test_rf2  = rf2.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "42c0855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19941\n",
      "           1       1.00      1.00      1.00     19921\n",
      "\n",
      "    accuracy                           1.00     39862\n",
      "   macro avg       1.00      1.00      1.00     39862\n",
      "weighted avg       1.00      1.00      1.00     39862\n",
      "\n",
      "Test accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54       829\n",
      "           1       0.94      0.94      0.94      6655\n",
      "\n",
      "    accuracy                           0.90      7484\n",
      "   macro avg       0.74      0.74      0.74      7484\n",
      "weighted avg       0.90      0.90      0.90      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Report: {}\".format(classification_report(pred_train_rf2, y_train_tf)))\n",
    "print(\"Test accuracy: {}\".format(classification_report(pred_test_rf2, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f024d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8972474612506681 0.7410540520700127\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pred_test_rf2, ytest), roc_auc_score(pred_test_rf2, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b36ca83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4e443",
   "metadata": {},
   "source": [
    "{'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': 'auto',\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd832889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de4c42ea",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "1. XGBoost with bag of words feature extraction performs best among all 4 models\n",
    "2. The model's performance can be improved using feature selection/dimensionality reduction on the data and hyperparameter optimization of the model\n",
    "\n",
    "#### Saving XGBoost Model and Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "834d6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vect = \"tfidf_vect.pkl\"\n",
    "# with open(tfidf_vect, 'wb') as file:\n",
    "#     pickle.dump(tfidf_vectorizer, file)\n",
    "\n",
    "# pkl_filename = \"tfidf_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(tfidf_model, file)\n",
    "    \n",
    "# pkl_filename = \"bow_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(bow_model, file)\n",
    "    \n",
    "# bow_vect = \"bow_vect.pkl\"\n",
    "# with open(bow_vect, 'wb') as file:\n",
    "#     pickle.dump(bow_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc75deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_filename = \"xgb_tf_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(xgb1, file)\n",
    "\n",
    "# pkl_filename = \"xgb_bow_model.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(xgb2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29032880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc6e0e2",
   "metadata": {},
   "source": [
    "## Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51e2ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_file = \"tfidf_model.pkl\"\n",
    "with open(tf_model_file, 'rb') as file:\n",
    "    tf_model = pickle.load(file)\n",
    "    \n",
    "xgtf_model_file = \"xgb_tf_model.pkl\"\n",
    "with open(xgtf_model_file, 'rb') as file:\n",
    "    xgtf_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2387ee40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7472751 , 0.25272486]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some = tf_model.transform(xtrain[1200:1201].to_list())\n",
    "xgtf_model.predict_proba(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca76101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27203    0\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[1200:1201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e8ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12800536",
   "metadata": {},
   "source": [
    "## Hyper-parameter Optimization:\n",
    "- XGBoost (Best Performing Model)\n",
    "- Prevent Overfitting (Using Random Search with Cross Validation & PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb62435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num=10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e8d5b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=30, scoring='accuracy', \n",
    "                      cv=3, verbose=2, random_state=42, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "656b5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fa151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f429ea43",
   "metadata": {},
   "source": [
    "## Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3f8d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joshua</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rebecca</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walker557</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviews_username                                        name  \\\n",
       "0           joshua   Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1        dorothy w  Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "2        dorothy w  Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "3          rebecca            K-Y Love Sensuality Pleasure Gel   \n",
       "4        walker557            K-Y Love Sensuality Pleasure Gel   \n",
       "\n",
       "   reviews_rating              reviews_date  \n",
       "0               5  2012-11-30T06:21:45.000Z  \n",
       "1               5  2017-07-09T00:00:00.000Z  \n",
       "2               5  2017-07-09T00:00:00.000Z  \n",
       "3               1  2016-01-06T00:00:00.000Z  \n",
       "4               1  2016-12-21T00:00:00.000Z  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = df[['reviews_username', 'name', 'reviews_rating', 'reviews_date']]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b9b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29936 entries, 0 to 29935\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   reviews_username  29936 non-null  object\n",
      " 1   name              29936 non-null  object\n",
      " 2   reviews_rating    29936 non-null  int64 \n",
      " 3   reviews_date      29896 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 935.6+ KB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "272d4a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24914, 271)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['reviews_username'].nunique(), ratings['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af93902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     271.000000\n",
       "mean      110.317343\n",
       "std       585.800600\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         8.000000\n",
       "75%        29.000000\n",
       "max      8525.000000\n",
       "Name: reviews_date, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating = ratings.groupby(['name'])['reviews_date'].count().reset_index()\n",
    "min_movie_rating['reviews_date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7cbc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861.8000000000006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(min_movie_rating['reviews_date'], 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231502d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65    Clorox Disinfecting Wipes Value Pack Scented 1...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating[min_movie_rating['reviews_date']==8525]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34540a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating.loc[65, 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f63ad21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8525, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings['name']=='Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37ac7b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42 Dual Drop Leaf Table with 2 Madrid Chairs\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5302050 15/16 FCT/HOSE ADAPTOR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Avery174 11-1/4 X 9-1/4 Index Maker Extra Wide...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Black Sister's Revenge (dvd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Blue Anchor Design Throw Pillow (18x18) - Rizz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bodycology Nourishing Body Cream, Pretty In Paris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Cal Lighting Led Dark Bronze Finish Metal Pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Candy Pink Plastic Cups, 20 pk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Carson-Dellosa Publishing Photographic Learnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Citrus Magic Instant Spot &amp; Stain Remover</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Clorox Ultimate Care Premium Bleach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Craft Punch Giga Scallop Circle 45 24687534 To...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Disney174 Jake And The Neverland Pirates 4 Pie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Elvis Presley - Girl Happy (cd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Every Man Jack Pomade Signature Mint Scent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Fantasy Fields Lil' Sports Fan Step Stool - Te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Germ Guardian174 Elite 3-In-1 Pet Pure True He...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Greyson Vintage Industrial Occasional Cocktail...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heinz Tomato Ketchup, 38oz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Herr's Baked Cheese Curls</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>High-Dome Floor Door Stop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Home Health Hairever Shampoo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Iman Luxury Moisturizing Lipstick, Black Brand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>JNH Lifestyles Goldstar 3 Person FAR Infrared ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Kenroy Home Table Lamp - Chrome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>La Tortilla Factory Hand Made Style Tortillas ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Lite Source Basic Ii 1-Lt Floor Lamp - Dark Br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Lite Source Reiko 1 Light Table Lamp - Orange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Noosa Honey Yogurt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Pacific Natural Foods Organic Beef Broth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Pearhead Id Bracelet Frame</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Pocket Watch Wall Clock Distressed Black - Yos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Progresso Traditional Chicken Rice With Vegeta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Progresso Traditional Meatball &amp; Rice Soup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Roommates No Place Like Home Peel Stick Wall D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Scotty Mini Double Ended Extender</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Sea Gull Lighting Ceiling Fan - White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Sea Gull Lighting One Light Wall/bath/vanity-B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Sloan Royal Urinal Flush Valve, 1.0 Gpf, Royal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Southern Enterprises Archer Fold-Away Home Bar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Stonyfield Yobaby Peach &amp; Pear Yogurt 4oz 6 Ct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Sunflower Swag With Metal Frame - Nearly Natural</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Tostitos Original Restaurant Style Tortilla Chips</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Udi's Pepperoni Pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Various - Country's Greatest Gospel:Gold Ed (cd)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Walkers Stem Ginger Shortbread</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Wallmount Server Cabinet (450mm, 9 RU)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Wedding Wishes Wedding Guest Book</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Wilton Black Dots Standard Baking Cups</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  reviews_date\n",
       "4        42 Dual Drop Leaf Table with 2 Madrid Chairs\"             1\n",
       "6                       5302050 15/16 FCT/HOSE ADAPTOR             0\n",
       "18   Avery174 11-1/4 X 9-1/4 Index Maker Extra Wide...             1\n",
       "35                        Black Sister's Revenge (dvd)             1\n",
       "36   Blue Anchor Design Throw Pillow (18x18) - Rizz...             1\n",
       "37   Bodycology Nourishing Body Cream, Pretty In Paris             1\n",
       "43   Cal Lighting Led Dark Bronze Finish Metal Pian...             1\n",
       "45                      Candy Pink Plastic Cups, 20 pk             1\n",
       "50   Carson-Dellosa Publishing Photographic Learnin...             1\n",
       "61           Citrus Magic Instant Spot & Stain Remover             1\n",
       "66                 Clorox Ultimate Care Premium Bleach             1\n",
       "72   Craft Punch Giga Scallop Circle 45 24687534 To...             1\n",
       "80   Disney174 Jake And The Neverland Pirates 4 Pie...             1\n",
       "83                     Elvis Presley - Girl Happy (cd)             1\n",
       "85          Every Man Jack Pomade Signature Mint Scent             1\n",
       "86   Fantasy Fields Lil' Sports Fan Step Stool - Te...             1\n",
       "92   Germ Guardian174 Elite 3-In-1 Pet Pure True He...             1\n",
       "94   Greyson Vintage Industrial Occasional Cocktail...             1\n",
       "99                          Heinz Tomato Ketchup, 38oz             1\n",
       "101                          Herr's Baked Cheese Curls             1\n",
       "102                          High-Dome Floor Door Stop             1\n",
       "105                       Home Health Hairever Shampoo             1\n",
       "110  Iman Luxury Moisturizing Lipstick, Black Brand...             1\n",
       "114  JNH Lifestyles Goldstar 3 Person FAR Infrared ...             1\n",
       "122                    Kenroy Home Table Lamp - Chrome             1\n",
       "134  La Tortilla Factory Hand Made Style Tortillas ...             1\n",
       "137  Lite Source Basic Ii 1-Lt Floor Lamp - Dark Br...             1\n",
       "138      Lite Source Reiko 1 Light Table Lamp - Orange             1\n",
       "167                                 Noosa Honey Yogurt             1\n",
       "174           Pacific Natural Foods Organic Beef Broth             1\n",
       "177                         Pearhead Id Bracelet Frame             1\n",
       "182          Pink Friday: Roman Reloaded Re-Up (w/dvd)             1\n",
       "189  Pocket Watch Wall Clock Distressed Black - Yos...             1\n",
       "193  Progresso Traditional Chicken Rice With Vegeta...             1\n",
       "195         Progresso Traditional Meatball & Rice Soup             1\n",
       "203  Roommates No Place Like Home Peel Stick Wall D...             1\n",
       "207                  Scotty Mini Double Ended Extender             0\n",
       "208              Sea Gull Lighting Ceiling Fan - White             1\n",
       "210  Sea Gull Lighting One Light Wall/bath/vanity-B...             1\n",
       "215  Sloan Royal Urinal Flush Valve, 1.0 Gpf, Royal...             1\n",
       "223  Southern Enterprises Archer Fold-Away Home Bar...             1\n",
       "231     Stonyfield Yobaby Peach & Pear Yogurt 4oz 6 Ct             1\n",
       "234   Sunflower Swag With Metal Frame - Nearly Natural             1\n",
       "245  Tostitos Original Restaurant Style Tortilla Chips             1\n",
       "252                              Udi's Pepperoni Pizza             1\n",
       "253   Various - Country's Greatest Gospel:Gold Ed (cd)             1\n",
       "261                     Walkers Stem Ginger Shortbread             1\n",
       "262             Wallmount Server Cabinet (450mm, 9 RU)             1\n",
       "265                  Wedding Wishes Wedding Guest Book             1\n",
       "267             Wilton Black Dots Standard Baking Cups             1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_movie_rating[min_movie_rating['reviews_date']<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5b5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21237e48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joshua',\n",
       " 'joshv',\n",
       " 'joshbart37',\n",
       " 'josh',\n",
       " 'joshr',\n",
       " 'josh4416',\n",
       " 'omyjosh',\n",
       " 'josh6918',\n",
       " 'joshua54354354351',\n",
       " 'joshandles',\n",
       " 'joshy',\n",
       " 'byjosh',\n",
       " 'joshuam02',\n",
       " 'joshc',\n",
       " 'joshweber04',\n",
       " 'josh3110',\n",
       " 'joshua21',\n",
       " 'joshjordan']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in ratings['reviews_username'].unique() if 'josh' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b2b856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24914.000000\n",
       "mean         1.199968\n",
       "std          0.771844\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max         41.000000\n",
       "Name: reviews_date, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_user_rating = ratings.groupby(['reviews_username'])['reviews_date'].count().reset_index()\n",
    "min_user_rating['reviews_date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f67951d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(min_user_rating['reviews_date'], 95), np.percentile(min_user_rating['reviews_date'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77778caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='reviews_date'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(min_user_rating['reviews_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17342723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_user_rating[min_user_rating['reviews_date']>=3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad64dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c4c613",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11440</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6974</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6974</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19327</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24205</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating              reviews_date\n",
       "0   11440      182       5  2012-11-30T06:21:45.000Z\n",
       "1    6974      140       5  2017-07-09T00:00:00.000Z\n",
       "2    6974      140       5  2017-07-09T00:00:00.000Z\n",
       "3   19327      120       1  2016-01-06T00:00:00.000Z\n",
       "4   24205      120       1  2016-12-21T00:00:00.000Z"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings.rename(columns={'reviews_username':'userId', 'name':'movieId', 'reviews_rating':'rating'})\n",
    "\n",
    "le_usr = LabelEncoder()\n",
    "le_usr = le_usr.fit(ratings['userId'])\n",
    "ratings['userId'] = le_usr.transform(ratings['userId'])\n",
    "\n",
    "le_name = LabelEncoder()\n",
    "le_name = le_name.fit(ratings['movieId'])\n",
    "ratings['movieId'] = le_name.fit_transform(ratings['movieId'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12e5e32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>24909</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-02T00:53:21.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12732</th>\n",
       "      <td>24909</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-12-02T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating              reviews_date\n",
       "9103    24909       65       5  2014-12-02T00:53:21.000Z\n",
       "12732   24909       65       5  2014-12-02T00:00:00.000Z"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings['userId']==24909]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5597eaec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zxcsdfd'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_usr.inverse_transform([24909])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000c2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3771662c",
   "metadata": {},
   "source": [
    "## User-User Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "934ba214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20955, 4), (8981, 4))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(ratings, test_size=0.30, random_state=42)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd876d5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0    1    2    3    4    5    6    7    8    9    ...  260  261  262  \\\n",
       "userId                                                     ...                  \n",
       "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "movieId  263  264  265  266  268  269  270  \n",
       "userId                                      \n",
       "1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 256 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = train.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "df_pivot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2c04303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0    1    2    3    4    5    6    7    8    9    ...  260  261  262  \\\n",
       "userId                                                     ...                  \n",
       "1        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "2        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "3        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "4        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "5        1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "\n",
       "movieId  263  264  265  266  268  269  270  \n",
       "userId                                      \n",
       "1        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "5        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_train = train.copy()\n",
    "dummy_train['rating'] = dummy_train['rating'].apply(lambda x: 0 if x>=1 else 1)\n",
    "dummy_train = dummy_train.pivot_table(index='userId', columns='movieId', values='rating').fillna(1)\n",
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63545935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18273"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb0cbedd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.        0.        ... 0.        0.9486833 0.       ]\n",
      " [0.        1.        1.        ... 0.        0.        0.       ]\n",
      " [0.        1.        1.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 1.        0.        1.       ]\n",
      " [0.9486833 0.        0.        ... 0.        1.        0.       ]\n",
      " [0.        0.        0.        ... 1.        0.        1.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the User Similarity Matrix using pairwise_distance function.\n",
    "user_correlation = 1 - pairwise_distances(df_pivot, metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99d008aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18273, 18273)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a958c9",
   "metadata": {},
   "source": [
    "### Adjusted Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbe9e500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.00496628 -0.00496628 ... -0.00496628  0.9485598\n",
      "  -0.00496628]\n",
      " [-0.00496628  1.          1.         ... -0.00392157 -0.00392157\n",
      "  -0.00392157]\n",
      " [-0.00496628  1.          1.         ... -0.00392157 -0.00392157\n",
      "  -0.00392157]\n",
      " ...\n",
      " [-0.00496628 -0.00392157 -0.00392157 ...  1.         -0.00392157\n",
      "   1.        ]\n",
      " [ 0.9485598  -0.00392157 -0.00392157 ... -0.00392157  1.\n",
      "  -0.00392157]\n",
      " [-0.00496628 -0.00392157 -0.00392157 ...  1.         -0.00392157\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "mean = np.nanmean(df_pivot, axis=1)\n",
    "df_subtracted = (df_pivot.T-mean).T\n",
    "\n",
    "user_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1e55451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18273, 18273)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ea3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd46e8c",
   "metadata": {},
   "source": [
    "## Evaluation: User-User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20289533",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = test[test.userId.isin(train.userId)]\n",
    "common_user_based_matrix = common.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "user_correlation_df = pd.DataFrame(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99c01645",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df['userId'] = df_subtracted.index\n",
    "user_correlation_df.set_index('userId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcc17757",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name = common.userId.tolist()\n",
    "user_correlation_df.columns = df_subtracted.index.tolist()\n",
    "\n",
    "user_correlation_df_1 = user_correlation_df[user_correlation_df.index.isin(list_name)]\n",
    "user_correlation_df_2 = user_correlation_df_1.T[user_correlation_df_1.T.index.isin(list_name)]\n",
    "user_correlation_df_3 = user_correlation_df_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68705fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3[user_correlation_df_3<0]=0\n",
    "common_user_predicted_ratings = np.dot(user_correlation_df_3, common_user_based_matrix.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff98c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test = common.copy()\n",
    "dummy_test['rating'] = dummy_test['rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "dummy_test = dummy_test.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5b4f0bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>260</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0    1    9    10   14   15   16   17   19   20   ...  253  254  255  \\\n",
       "userId                                                     ...                  \n",
       "15       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "17       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "20       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "44       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "92       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "movieId  256  257  258  260  263  264  268  \n",
       "userId                                      \n",
       "15       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "44       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "92       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_user_predicted_ratings = np.multiply(common_user_predicted_ratings, dummy_test)\n",
    "common_user_predicted_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f898eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(feature_range=(1, 5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:400: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:401: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "X = common_user_predicted_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1be25429",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ = common.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0edbdd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.534229490238383\n"
     ]
    }
   ],
   "source": [
    "rmse = (sum(sum((common_ - y )**2))/total_non_nan)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ede7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d6b6ebe",
   "metadata": {},
   "source": [
    "## Prediction: User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1d9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratings_model(ratings):\n",
    "    df_pivot_w = ratings.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    mean = np.nanmean(df_pivot_w, axis=1)\n",
    "    df_subtracted_w = (df_pivot_w.T-mean).T\n",
    "\n",
    "    user_correlation_w = 1 - pairwise_distances(df_subtracted_w.fillna(0), metric='cosine')\n",
    "    user_correlation_w[np.isnan(user_correlation_w)] = 0\n",
    "    \n",
    "    user_correlation_w[user_correlation_w<0]=0\n",
    "    d_train = ratings.copy()\n",
    "    d_train['rating'] = d_train['rating'].apply(lambda x: 0 if x>=1 else 1)\n",
    "    d_train = d_train.pivot_table(index='userId', columns='movieId', values='rating').fillna(1)\n",
    "    \n",
    "    user_predicted_ratings2 = np.dot(user_correlation_w, df_pivot_w.fillna(0))\n",
    "    user_final_rating2 = np.multiply(user_predicted_ratings2, d_train)\n",
    "    return user_final_rating2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccea21fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# final_model = create_ratings_model(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1602914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_filename = \"user_final_rating.pkl\"\n",
    "# with open(pkl_filename, 'wb') as file:\n",
    "#     pickle.dump(user_final_rating2, file)\n",
    "\n",
    "# user_encoding = \"user_encoding.pkl\"\n",
    "# with open(user_encoding, 'wb') as file:\n",
    "#     pickle.dump(le_usr, file)\n",
    "    \n",
    "# movie_name_encoding = \"movie_name_encoding.pkl\"\n",
    "# with open(movie_name_encoding, 'wb') as file:\n",
    "#     pickle.dump(le_name, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e503c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3917e88",
   "metadata": {},
   "source": [
    "# Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c993bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "data = pd.read_csv('Model/sample30.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d3542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_file = \"Model/user_final_rating.pkl\"\n",
    "with open(final_model_file, 'rb') as file:\n",
    "    final_model = pickle.load(file)\n",
    "    \n",
    "user_encoding = \"Model/user_encoding.pkl\"\n",
    "with open(user_encoding, 'rb') as file:\n",
    "    le_usr = pickle.load(file)\n",
    "\n",
    "movie_name_encoding = \"Model/movie_name_encoding.pkl\"\n",
    "with open(movie_name_encoding, 'rb') as file:\n",
    "    le_name = pickle.load(file)\n",
    "    \n",
    "tfidf_vect = \"Model/tfidf_vect.pkl\"\n",
    "with open(tfidf_vect, 'rb') as file:\n",
    "    tf_vect = pickle.load(file)\n",
    "    \n",
    "tf_model_file = \"Model/tfidf_model.pkl\"\n",
    "with open(tf_model_file, 'rb') as file:\n",
    "    tf_model = pickle.load(file)\n",
    "    \n",
    "xgtf_model_file = \"Model/xgb_tf_model.pkl\"\n",
    "with open(xgtf_model_file, 'rb') as file:\n",
    "    xgtf_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba35707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9b4aefe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your user name: 5643\n",
      "['cricri']\n"
     ]
    }
   ],
   "source": [
    "# Take the user ID as input.\n",
    "user_input = int(input(\"Enter your user name: \"))\n",
    "print(le_usr.inverse_transform([user_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f7eaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>movie_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Clorox Disinfecting Wipes Value Pack Scented 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>Mike Dave Need Wedding Dates (dvd + Digital)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Burt's Bees Lip Shimmer, Raisin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Aussie Aussome Volume Shampoo, 13.5 Oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>Cheetos Crunchy Flamin' Hot Cheese Flavored Sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93</td>\n",
       "      <td>Godzilla 3d Includes Digital Copy Ultraviolet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>161</td>\n",
       "      <td>Nearly Natural 5.5' Bamboo W/decorative Planter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>239</td>\n",
       "      <td>The Resident Evil Collection 5 Discs (blu-Ray)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>Red (special Edition) (dvdvideo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>Clorox Disinfecting Bathroom Cleaner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>179</td>\n",
       "      <td>Physicians Formula Mineral Wear Talc-Free Mine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>187</td>\n",
       "      <td>Pleasant Hearth Diamond Fireplace Screen - Esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>181</td>\n",
       "      <td>Pinaud Clubman Styling Gel, Superhold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>178</td>\n",
       "      <td>Pendaflex174 Divide It Up File Folder, Multi S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>182</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>183</td>\n",
       "      <td>Planes: Fire Rescue (2 Discs) (includes Digita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>177</td>\n",
       "      <td>Pearhead Id Bracelet Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>184</td>\n",
       "      <td>Plano Mini-Magnum 13-Compartment Tackle Box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>185</td>\n",
       "      <td>Pleasant Hearth 1,800 sq ft Wood Burning Stove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>186</td>\n",
       "      <td>Pleasant Hearth 7.5 Steel Grate, 30 5 Bar - Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId                                         movie_name\n",
       "0        65  Clorox Disinfecting Wipes Value Pack Scented 1...\n",
       "1       151       Mike Dave Need Wedding Dates (dvd + Digital)\n",
       "2        41                    Burt's Bees Lip Shimmer, Raisin\n",
       "3        15             Aussie Aussome Volume Shampoo, 13.5 Oz\n",
       "4        55  Cheetos Crunchy Flamin' Hot Cheese Flavored Sn...\n",
       "5        93  Godzilla 3d Includes Digital Copy Ultraviolet ...\n",
       "6       161    Nearly Natural 5.5' Bamboo W/decorative Planter\n",
       "7       239     The Resident Evil Collection 5 Discs (blu-Ray)\n",
       "8       200                   Red (special Edition) (dvdvideo)\n",
       "9        64               Clorox Disinfecting Bathroom Cleaner\n",
       "10      179  Physicians Formula Mineral Wear Talc-Free Mine...\n",
       "11      187  Pleasant Hearth Diamond Fireplace Screen - Esp...\n",
       "12      181              Pinaud Clubman Styling Gel, Superhold\n",
       "13      178  Pendaflex174 Divide It Up File Folder, Multi S...\n",
       "14      182          Pink Friday: Roman Reloaded Re-Up (w/dvd)\n",
       "15      183  Planes: Fire Rescue (2 Discs) (includes Digita...\n",
       "16      177                         Pearhead Id Bracelet Frame\n",
       "17      184        Plano Mini-Magnum 13-Compartment Tackle Box\n",
       "18      185  Pleasant Hearth 1,800 sq ft Wood Burning Stove...\n",
       "19      186  Pleasant Hearth 7.5 Steel Grate, 30 5 Bar - Black"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = final_model.loc[user_input].sort_values(ascending=False)[0:20].to_frame()\n",
    "d = d.reset_index()\n",
    "d.drop(d.columns[1], axis=1, inplace=True)\n",
    "\n",
    "movie_name = le_name.inverse_transform(d['movieId'])\n",
    "d['movie_name'] = movie_name\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d0aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae8edef9",
   "metadata": {},
   "source": [
    "### Selecting top 5 movies (Positive sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e38ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review_pipeline(df):\n",
    "#     df['reviews_title'] = df['reviews_title'].fillna('NF')\n",
    "#     df = df.reset_index(drop=True)\n",
    "    \n",
    "#     start_ = time.time()\n",
    "#     for i in range(len(df)):\n",
    "#         if df.loc[i,'reviews_title'] == 'NF':\n",
    "#             if df.loc[i, 'user_sentiment'] == 'Positive':\n",
    "#                 df.loc[i,'reviews_title']='Good'\n",
    "#             if df.loc[i, 'user_sentiment'] == 'Negative':\n",
    "#                 df.loc[i,'reviews_title']='Bad'\n",
    "#     print(time.time()-start_)\n",
    "            \n",
    "    stemmer = PorterStemmer()\n",
    "    def preprocess(document):\n",
    "        'changes document to lower case and removes stopwords'\n",
    "        document = document.lower()\n",
    "        words = word_tokenize(document)\n",
    "        words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "        document = \" \".join(words)\n",
    "        return document\n",
    "    \n",
    "    start_ = time.time()\n",
    "#     df['reviews_text'] = df['reviews_title']+' '+df['reviews_text']\n",
    "    df['proc_reviews_text'] = df['reviews_text'].apply(preprocess)\n",
    "    print(time.time()-start_)\n",
    "    return df['proc_reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114d4854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18799, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Aussie Aussome Volume Shampoo, 13.5 Oz</td>\n",
       "      <td>Did Absolutley Nothing For Me</td>\n",
       "      <td>I have very oily, fine hair and this shampoo j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  \\\n",
       "0     Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1072     Aussie Aussome Volume Shampoo, 13.5 Oz   \n",
       "\n",
       "                      reviews_title  \\\n",
       "0                      Just Awesome   \n",
       "1072  Did Absolutley Nothing For Me   \n",
       "\n",
       "                                           reviews_text  \n",
       "0     i love this album. it's very good. more to the...  \n",
       "1072  I have very oily, fine hair and this shampoo j...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = data[data['name'].isin(d['movie_name'].to_list())]\n",
    "filter_df = filter_df[~filter_df['reviews_text'].isnull()]\n",
    "filter_df = filter_df[['name', 'reviews_title', 'reviews_text']]\n",
    "print(filter_df.shape)\n",
    "filter_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e54fa0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.36874914169312\n",
      "(18799, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>proc_reviews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>love album . 's good . hip hop side current po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Aussie Aussome Volume Shampoo, 13.5 Oz</td>\n",
       "      <td>Did Absolutley Nothing For Me</td>\n",
       "      <td>I have very oily, fine hair and this shampoo j...</td>\n",
       "      <td>oili , fine hair shampoo made hair look dirtie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  \\\n",
       "0     Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1072     Aussie Aussome Volume Shampoo, 13.5 Oz   \n",
       "\n",
       "                      reviews_title  \\\n",
       "0                      Just Awesome   \n",
       "1072  Did Absolutley Nothing For Me   \n",
       "\n",
       "                                           reviews_text  \\\n",
       "0     i love this album. it's very good. more to the...   \n",
       "1072  I have very oily, fine hair and this shampoo j...   \n",
       "\n",
       "                                      proc_reviews_text  \n",
       "0     love album . 's good . hip hop side current po...  \n",
       "1072  oili , fine hair shampoo made hair look dirtie...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df['proc_reviews_text'] = process_review_pipeline(filter_df)\n",
    "print(filter_df.shape)\n",
    "filter_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc94b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bebc5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18799, 13290)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tf_model.transform(filter_df['proc_reviews_text'])\n",
    "tf_df = pd.DataFrame(tf.toarray(), columns=tf_vect.get_feature_names())\n",
    "tf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "673feffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>proc_reviews_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>love album . 's good . hip hop side current po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Aussie Aussome Volume Shampoo, 13.5 Oz</td>\n",
       "      <td>Did Absolutley Nothing For Me</td>\n",
       "      <td>I have very oily, fine hair and this shampoo j...</td>\n",
       "      <td>oili , fine hair shampoo made hair look dirtie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>Aussie Aussome Volume Shampoo, 13.5 Oz</td>\n",
       "      <td>Why the change</td>\n",
       "      <td>I've used your volume product for years but al...</td>\n",
       "      <td>'ve use volum product year sudden remov 2-in-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>Aussie Aussome Volume Shampoo, 13.5 Oz</td>\n",
       "      <td>can't use anymore</td>\n",
       "      <td>I have been using aussome volume for over 10 y...</td>\n",
       "      <td>use aussom volum 10 year except use call real ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>Aussie Aussome Volume Shampoo, 13.5 Oz</td>\n",
       "      <td>not worth it</td>\n",
       "      <td>i tried this hoping it would give great result...</td>\n",
       "      <td>tri hope would give great result . opposit eff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  \\\n",
       "0     Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1072     Aussie Aussome Volume Shampoo, 13.5 Oz   \n",
       "1073     Aussie Aussome Volume Shampoo, 13.5 Oz   \n",
       "1074     Aussie Aussome Volume Shampoo, 13.5 Oz   \n",
       "1075     Aussie Aussome Volume Shampoo, 13.5 Oz   \n",
       "\n",
       "                      reviews_title  \\\n",
       "0                      Just Awesome   \n",
       "1072  Did Absolutley Nothing For Me   \n",
       "1073                 Why the change   \n",
       "1074              can't use anymore   \n",
       "1075                   not worth it   \n",
       "\n",
       "                                           reviews_text  \\\n",
       "0     i love this album. it's very good. more to the...   \n",
       "1072  I have very oily, fine hair and this shampoo j...   \n",
       "1073  I've used your volume product for years but al...   \n",
       "1074  I have been using aussome volume for over 10 y...   \n",
       "1075  i tried this hoping it would give great result...   \n",
       "\n",
       "                                      proc_reviews_text  sentiment  \n",
       "0     love album . 's good . hip hop side current po...          1  \n",
       "1072  oili , fine hair shampoo made hair look dirtie...          1  \n",
       "1073  've use volum product year sudden remov 2-in-1...          1  \n",
       "1074  use aussom volum 10 year except use call real ...          1  \n",
       "1075  tri hope would give great result . opposit eff...          1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = xgtf_model.predict_proba(tf_df)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "filter_df['sentiment'] = best_preds\n",
    "filter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "babc0592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18673, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clorox Disinfecting Wipes Value Pack Scented 1...</td>\n",
       "      <td>8430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Godzilla 3d Includes Digital Copy Ultraviolet ...</td>\n",
       "      <td>3324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clorox Disinfecting Bathroom Cleaner</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Planes: Fire Rescue (2 Discs) (includes Digita...</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burt's Bees Lip Shimmer, Raisin</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  sentiment\n",
       "4   Clorox Disinfecting Wipes Value Pack Scented 1...       8430\n",
       "5   Godzilla 3d Includes Digital Copy Ultraviolet ...       3324\n",
       "3                Clorox Disinfecting Bathroom Cleaner       2032\n",
       "13  Planes: Fire Rescue (2 Discs) (includes Digita...       1143\n",
       "1                     Burt's Bees Lip Shimmer, Raisin        873"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = filter_df[filter_df['sentiment']==1]\n",
    "print(final_df.shape)\n",
    "final_df = final_df.groupby('name')['sentiment'].sum().reset_index()\n",
    "final_df = final_df.sort_values(by='sentiment', ascending=False)\n",
    "final_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "759581e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total',\n",
       " 'Godzilla 3d Includes Digital Copy Ultraviolet 3d/2d Blu-Ray/dvd',\n",
       " 'Clorox Disinfecting Bathroom Cleaner',\n",
       " 'Planes: Fire Rescue (2 Discs) (includes Digital Copy) (blu-Ray/dvd)',\n",
       " \"Burt's Bees Lip Shimmer, Raisin\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[:5]['name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8cee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00169b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
